{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"methods.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCPDJYlHubzM/9VitGmDH5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tqdm import tqdm_notebook\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, \\\n","    recall_score, f1_score, log_loss, auc, classification_report, confusion_matrix, \\\n","    precision_recall_curve, roc_curve\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from typing import List\n","\n","RAND = 10"],"metadata":{"id":"9FXzUMyM92zV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"64EEyMJC6_ka"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_difference(data: pd.DataFrame, x: str, y:str, fig_size: tuple) -> None:\n","    \"\"\"\n","    A function that shows what proportion of objects \n","    of one class compared to others, indicating the attribute.\n","    :param data: DataFrame\n","    :param x: feature for analysis\n","    :param y: target\n","    :param fig_size: size of graph\n","    :return: None\n","    \"\"\"\n","    group_data = (data.groupby([y])[x]\n","                .value_counts(normalize=True)\n","                .rename('percentage')\n","                .mul(100)\n","                .reset_index()\n","                .sort_values('percentage', ascending=False))\n","    \n","    dif = group_data.loc[group_data[y]==0].groupby(x)[['percentage']].max() - \\\n","            group_data.loc[group_data[y]==1].groupby(x)[['percentage']].max()\n","    dif = dif.sort_values(by='percentage',ascending=False).reset_index()\n","\n","    dif.rename(columns={'percentage': 'difference'}, inplace=True)\n","    \n","    plt.figure(figsize=fig_size)\n","    sns.barplot(data = dif, x='difference', y=x, orient='h');"],"metadata":{"id":"EXDabm3o5kxn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B0egwUhrnt-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def bar_plot_group(data: pd.DataFrame, \n","                   x: str, \n","                   y: str, \n","                   orient: str, \n","                   fig_size: tuple, \n","                   plot_values: bool,\n","                   trashhold: float = 0.0) -> None:\n","    \"\"\"\n","    The function of constructing the distribution of \n","    categorical features in the context of the target\n","    \n","    :param data: DataFrame\n","    :param x: feature for analysis\n","    :param y: target\n","    :param orient: orientation graph\n","    :param fig_size: size of graph\n","    :param plot_values: is plot values?\n","    :return: None\n","    \"\"\"\n","    ax = plt.figure(figsize=fig_size)\n","\n","    group_data = (data.groupby([y])[x]\n","                  .value_counts(normalize=True)\n","                  .rename('percentage')\n","                  .mul(100)\n","                  .reset_index()\n","                  .sort_values('percentage', ascending=False))\n","    \n","    if orient == 'h':\n","      ax = sns.barplot(x=\"percentage\", \n","                       y=x, \n","                       hue=y, \n","                       data=group_data.loc[group_data['percentage'] > trashhold], \n","                       palette='rocket', \n","                       orient=orient)\n","    else:\n","      ax = sns.barplot(x=x, \n","                       y=\"percentage\", \n","                       hue=y, \n","                       data=group_data.loc[group_data['percentage'] > trashhold], \n","                       palette='rocket')\n","      \n","    ax.legend(loc='upper right')\n","    plt.xticks(rotation=20)\n","\n","    if plot_values:\n","      plot_text(ax)"],"metadata":{"id":"qsZvGPyp4SAp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WJWXXMXaqerY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def data_split(data: pd.DataFrame,\n","               split_per_year: bool,\n","               test_size: float,\n","               random_state: int) -> pd.DataFrame:\n","    \"\"\"\n","    Function for split data\n","    :param data: your data for split\n","    :param split_per_year: is split data per year or not\n","    :param test_size: size of test samples\n","    :param random_state: fixing the random state\n","    :return: np.array for labels and pd.DataFrame for object with features\n","    \"\"\"\n","    if split_per_year:\n","      train_data = data[data['ST_YEAR'].isin([2018, 2019])]\n","      test_data = data[data['ST_YEAR'] == 2020]\n","      x_train = train_data.drop('DEBT', axis=1)\n","      y_train = train_data.DEBT.values\n","      x_test = test_data.drop('DEBT', axis=1)\n","      y_test = test_data.DEBT.values\n","    else:\n","      X = data.drop('DEBT', axis = 1)\n","      y = data.DEBT.values\n","      x_train, x_test, y_train, y_test = train_test_split(X, \n","                                                          y, \n","                                                          random_state=random_state, \n","                                                          shuffle=True, test_size=test_size, \n","                                                          stratify=y)\n","      \n","    print('x_train:', x_train.shape)\n","    print('y_train:', y_train.shape)\n","    print('x_test:', x_test.shape)\n","    print('y_test:', y_test.shape)\n","    \n","    return x_train, y_train, x_test, y_test\n"],"metadata":{"id":"_fOSwX7YzeLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-b1QRPBdqfpY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def lgb_f1_score(y_true: pd.DataFrame, y_pred: np.array) -> float:\n","    \"\"\"\n","    Custom F1 metric for Lightgbm\n","    :param y_true: true labels\n","    :param y_pred: predict model labels\n","    :return: name, f1 score, is_higher_better\n","    For more information look \n","    https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html#lightgbm.LGBMRegressor.fit\n","    \"\"\"\n","    y_pred = np.round(y_pred)  # scikits f1 doesn't like probabilities\n","\n","    return 'f1', f1_score(y_true, y_pred), True"],"metadata":{"id":"N1SsAOhD9gDc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5IZ0mCXWnz6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def check_overfitting(model,\n","                      x_train: pd.DataFrame,\n","                      y_train: pd.DataFrame,\n","                      x_test: pd.DataFrame,\n","                      y_test: pd.DataFrame) -> None:\n","    \"\"\"\n","    Check overfitting function\n","    :param model: yor model for checking\n","    :param x_train: train dataframe\n","    :param y_train: train labels\n","    :param x_test: test dataframe\n","    :param y_test: test labels\n","    :return: None\n","    \"\"\"\n","    train_pred = model.predict(x_train)\n","    test_pred = model.predict(x_test)\n","    F1_train = f1_score(y_train, train_pred)\n","    F1_test = f1_score(y_test, test_pred)\n","\n","    print(f'F1 Train: %.3f' % F1_train)\n","    print(f'F1 Test: %.3f' % F1_test)\n","\n","    if F1_test / F1_train < 0.9:\n","        print('There is overfitting')\n","    else:\n","        print('No overfitting')"],"metadata":{"id":"NYnPmFHT9i0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EYffUhw5qggb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_metrics(y_test: pd.DataFrame, \n","                y_pred: np.array, \n","                y_score: np.array, \n","                name: str) -> pd.DataFrame:\n","    \"\"\"\n","    Calculate different classification metrics\n","    :param y_test: true labels\n","    :param y_pred: model predict labels\n","    :param y_score: model predict probabilities\n","    :param name: name of model\n","    :return: result of calculation\n","    \"\"\"\n","    df_metrics = pd.DataFrame()\n","\n","    df_metrics['model'] = [name]\n","\n","    df_metrics['Accuracy'] = [accuracy_score(y_test, y_pred)]\n","    df_metrics['ROC_AUC'] = [roc_auc_score(y_test, y_score)]\n","    df_metrics['Precision'] = [precision_score(y_test, y_pred)]\n","    df_metrics['Recall'] = [recall_score(y_test, y_pred)]\n","    df_metrics['f1'] = [f1_score(y_test, y_pred)]\n","    df_metrics['Logloss'] = [log_loss(y_test, y_score)]\n","\n","    return df_metrics"],"metadata":{"id":"2fz8zgpQ9mAK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9GXVaF-KqhPQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def correlation_features_to_drop(data: pd.DataFrame,\n","                                 method: str,\n","                                 weak_value: float,\n","                                 strong_value: float,\n","                                 figsize: tuple,\n","                                 plot: bool) -> List:\n","    \"\"\"\n","    Function for generating a list of strongly correlated features, and outputting a Heatmap\n","    :param data: you data\n","    :param method: method of calculate correlation ex: 'spearman' or 'pearson'\n","    :param weak_value: threshold of weak correlation\n","    :param strong_value: threshold of strong correlation\n","    :param figsize: size of heatmap\n","    :param plot: whether to draw a Heatmap\n","    :return: list of name features to drop\n","    \"\"\"\n","    corr = data.corr(method=method)\n","    corr_matrix = corr\n","    corr_matrix[corr_matrix < abs(weak_value)] = 0\n","    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n","    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool))\n","\n","    to_drop = [cols for cols in upper.columns if any(upper[cols] > strong_value)]\n","\n","    if plot:\n","        plt.figure(figsize=figsize)\n","        sns.heatmap(corr_matrix, annot=True, mask=mask)\n","\n","    return to_drop\n"],"metadata":{"id":"F22G4Z869sBv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bP6IEVE2qh5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def base_models_fit_compare(dict_of_models: dict,\n","                            x_train: pd.DataFrame,\n","                            y_train: np.array,\n","                            x_test: pd.DataFrame,\n","                            y_test: np.array) -> pd.DataFrame:\n","    \"\"\"\n","    Function for quick comparison of metrics of base models, for subsequent selection\n","    :param dict_of_models: dict of models for comparison\n","    :param x_train: train data\n","    :param y_train: train labels\n","    :param x_test: test data\n","    :param y_test: test labels\n","    :return: DataFrame with calculated metrics for each model\n","    \"\"\"\n","    metrics = pd.DataFrame()\n","\n","    X_train, x_val, Y_train, y_val = train_test_split(x_train, \n","                                                      y_train, \n","                                                      test_size=0.2, \n","                                                      random_state=RAND, \n","                                                      stratify=y_train)\n","    \n","\n","    for i in tqdm_notebook(dict_of_models):\n","      \n","        model = dict_of_models[i]\n","\n","        if i in ['LR', 'DT', 'RFC', 'KNN', 'Lightgbm']:\n","            model.fit(x_train, y_train)\n","        else:\n","            model.fit(X_train, \n","                     Y_train, \n","                     verbose=False,\n","                     eval_set=[(x_val, y_val)],\n","                     early_stopping_rounds=100)\n","\n","        y_pred = model.predict(x_test)\n","        y_score = model.predict_proba(x_test)[:, 1]\n","\n","        print(f'Model: {i}')\n","\n","        check_overfitting(model=model, \n","                         x_train=x_train,\n","                         y_train=y_train, \n","                         x_test=x_test, \n","                         y_test=y_test)\n","\n","        print('------------\\n')\n","\n","        metrics = metrics.append(get_metrics(y_test, y_pred, y_score, i))\n","\n","    return metrics"],"metadata":{"id":"2_bvUi2k9vYu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oQCpqnwhqi1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def change_mark(arg: str) -> int:\n","    \"\"\"\n","    Function for parsing MARK column\n","    :param arg: value of MARK\n","    :return: new value\n","    \"\"\"\n","    lst = ['неявка', 'незач', 'осв']\n","    \n","    if arg in lst:\n","        arg = 2\n","    elif arg == 'зачет':\n","        arg = 5\n","    else:\n","        arg = int(arg)\n","        \n","    return arg"],"metadata":{"id":"w-IJB4_89x9k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IQ6nzPGeqjkn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_text(ax: plt.figure) -> None:\n","    \"\"\"\n","    Function for labeling values on a chart\n","    :param ax: you figure\n","    :return: None\n","    \"\"\"\n","    for p in ax.patches:\n","      \n","        percentage = '{:.1f}%'.format(p.get_height())\n","\n","        ax.annotate(\n","            percentage,\n","            (p.get_x() + p.get_width() / 2., p.get_height()),\n","            ha='center',\n","            va='center',\n","            xytext=(0, 10),\n","            textcoords='offset points',\n","            fontsize=14)\n"],"metadata":{"id":"psMbTnnkF8BN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Cdsncu4VurDJ"},"execution_count":null,"outputs":[]}]}